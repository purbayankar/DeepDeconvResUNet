{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "25 gb landslide segmentation ResUNet.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/purbayankar/DeepDeconvResUNet/blob/main/25_gb_landslide_segmentation_ResUNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M6oXQwiQa2xr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4201fcde-9bc7-4063-d25e-c7289c1849e6"
      },
      "source": [
        "# Mount Google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.activity.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "4/1AY0e-g7kJy4z1iOsC0YYZ2f-KlI7Vy6Lsok6pjMy2bPAis0XcVDxJCrYWn8\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ql9l2Hx5aIt4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "737e747a-80b4-4002-8297-59c82b44dc02"
      },
      "source": [
        "# Import libraries\n",
        "\n",
        "import tensorflow as  tf\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "from datetime import datetime\n",
        "from packaging import version\n",
        "\n",
        "%tensorflow_version 2.x\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import *\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.optimizers import *\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(\"TensorFlow version: \", tf.__version__)\n",
        "assert version.parse(tf.__version__).release[0] >= 2, \\\n",
        "    \"This notebook requires TensorFlow 2.0 or above.\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow version:  2.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_mcRo4faN7P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "818e8f2e-608b-4087-cfdd-fa9f48ba0fdc"
      },
      "source": [
        "# Install segmetation_models library (https://github.com/qubvel/segmentation_models)\n",
        "!pip install segmentation_models"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting segmentation_models\n",
            "  Downloading https://files.pythonhosted.org/packages/da/b9/4a183518c21689a56b834eaaa45cad242d9ec09a4360b5b10139f23c63f4/segmentation_models-1.0.1-py3-none-any.whl\n",
            "Collecting efficientnet==1.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/97/82/f3ae07316f0461417dc54affab6e86ab188a5a22f33176d35271628b96e0/efficientnet-1.0.0-py3-none-any.whl\n",
            "Collecting keras-applications<=1.0.8,>=1.0.7\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 3.9MB/s \n",
            "\u001b[?25hCollecting image-classifiers==1.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/81/98/6f84720e299a4942ab80df5f76ab97b7828b24d1de5e9b2cbbe6073228b7/image_classifiers-1.0.0-py3-none-any.whl\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.6/dist-packages (from efficientnet==1.0.0->segmentation_models) (0.16.2)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras-applications<=1.0.8,>=1.0.7->segmentation_models) (1.19.5)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications<=1.0.8,>=1.0.7->segmentation_models) (2.10.0)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (1.1.1)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (3.2.2)\n",
            "Requirement already satisfied: scipy>=0.19.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (1.4.1)\n",
            "Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (7.0.0)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (2.4.1)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py->keras-applications<=1.0.8,>=1.0.7->segmentation_models) (1.15.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation_models) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation_models) (2.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation_models) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation_models) (1.3.1)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.0->scikit-image->efficientnet==1.0.0->segmentation_models) (4.4.2)\n",
            "Installing collected packages: keras-applications, efficientnet, image-classifiers, segmentation-models\n",
            "Successfully installed efficientnet-1.0.0 image-classifiers-1.0.0 keras-applications-1.0.8 segmentation-models-1.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tOLxdz3LaQeA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abc5bb1f-468c-4aa6-c83d-d37e0cfe1cd8"
      },
      "source": [
        "# Load segmentation)models library \n",
        "%env SM_FRAMEWORK=tf.keras\n",
        "import segmentation_models as sm"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "env: SM_FRAMEWORK=tf.keras\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9enf9eeJaS77"
      },
      "source": [
        "X_train = np.load(\"/content/drive/My Drive/data/X_train_aug.npy\")\n",
        "Y_train = np.load(\"/content/drive/My Drive/data/Y_train_aug.npy\")\n",
        "\n",
        "# Load test data - Area 1\n",
        "X_test_area_1 = np.load(\"/content/drive/My Drive/data/X_test_area_1.npy\")\n",
        "Y_test_area_1 = np.load(\"/content/drive/My Drive/data/Y_test_area_1.npy\")\n",
        "\n",
        "# Load test data - Area 2\n",
        "X_test_area_2 = np.load(\"/content/drive/My Drive/data/X_test_area_2.npy\")\n",
        "Y_test_area_2 = np.load(\"/content/drive/My Drive/data/Y_test_area_2.npy\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1v2regsLaXW7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bbc5955f-f1d0-48f2-a130-cf56baf39fca"
      },
      "source": [
        "# Evaluate data dimensions\n",
        "print(f\"X_train shape: {X_train.shape}, Y_train shape: {Y_train.shape}\\nX_test_area_1 shape: {X_test_area_1.shape}, Y_test_area_1 shape: {Y_test_area_1.shape},\\nX_test_area_2 shape: {X_test_area_2.shape}, Y_test_area_2 shape: {Y_test_area_2.shape}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train shape: (10228, 128, 128, 6), Y_train shape: (10228, 128, 128, 1)\n",
            "X_test_area_1 shape: (1, 1024, 1024, 6), Y_test_area_1 shape: (1, 1024, 1024, 1),\n",
            "X_test_area_2 shape: (1, 1024, 1024, 6), Y_test_area_2 shape: (1, 1024, 1024, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6VCpy13aabMe"
      },
      "source": [
        "# Evaluation Metrics - Precision, Recall, FScore, IoU\n",
        "metrics = [sm.metrics.Precision(threshold=0.5),sm.metrics.Recall(threshold=0.5),sm.metrics.FScore(threshold=0.5,beta=1),sm.metrics.IOUScore(threshold=0.5)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5tbf_7y4mZ3d"
      },
      "source": [
        "### Network Deconvolution Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kCOtUOcZadza",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a73627a-9b6a-4296-f51f-23a20024a3f0"
      },
      "source": [
        "import math\n",
        "import tensorflow as tf\n",
        "tf.config.experimental_run_functions_eagerly(True)\n",
        "from tensorflow.python.keras.layers.convolutional import Conv\n",
        "from tensorflow.python.keras.utils import conv_utils\n",
        "\n",
        "\n",
        "class BiasHeUniform(tf.keras.initializers.VarianceScaling):\n",
        "    def __init__(self, seed=None):\n",
        "        super(BiasHeUniform, self).__init__(scale=1. / 3., mode='fan_in', distribution='uniform', seed=seed)\n",
        "\n",
        "\n",
        "# iteratively solve for inverse sqrt of a matrix\n",
        "def isqrt_newton_schulz_autograd(A: tf.Tensor, numIters: int):\n",
        "    dim = tf.shape(A)[0]\n",
        "    normA = tf.norm(A, ord='fro', axis=[0, 1])\n",
        "    Y = A / normA\n",
        "\n",
        "    with tf.device(A.device):\n",
        "        I = tf.eye(dim, dtype=A.dtype)\n",
        "        Z = tf.eye(dim, dtype=A.dtype)\n",
        "\n",
        "    for i in range(numIters):\n",
        "        T = 0.5 * (3.0 * I - tf.matmul(Z, Y))\n",
        "        Y = tf.matmul(Y, T)\n",
        "        Z = tf.matmul(T, Z)\n",
        "\n",
        "    A_isqrt = Z / tf.sqrt(normA)\n",
        "    return A_isqrt\n",
        "\n",
        "\n",
        "def isqrt_newton_schulz_autograd_batch(A: tf.Tensor, numIters: int):\n",
        "    Ashape = tf.shape(A)  # [batch, _, C]\n",
        "    batchSize, dim = Ashape[0], Ashape[-1]\n",
        "\n",
        "    normA = tf.reshape(A, (batchSize, -1))\n",
        "    normA = tf.norm(normA, ord=2, axis=1)\n",
        "    normA = tf.reshape(normA, [batchSize, 1, 1])\n",
        "\n",
        "    Y = A / normA\n",
        "\n",
        "    with tf.device(A.device):\n",
        "        I = tf.expand_dims(tf.eye(dim, dtype=A.dtype), 0)\n",
        "        Z = tf.expand_dims(tf.eye(dim, dtype=A.dtype), 0)\n",
        "\n",
        "        I = tf.broadcast_to(I, Ashape)\n",
        "        Z = tf.broadcast_to(Z, Ashape)\n",
        "\n",
        "    for i in range(numIters):\n",
        "        T = 0.5 * (3.0 * I - tf.matmul(Z, Y))\n",
        "        Y = tf.matmul(Y, T)\n",
        "        Z = tf.matmul(T, Z)\n",
        "\n",
        "    A_isqrt = Z / tf.sqrt(normA)\n",
        "\n",
        "    return A_isqrt\n",
        "\n",
        "\n",
        "class ChannelDeconv2D(tf.keras.layers.Layer):\n",
        "    def __init__(self, block, eps=1e-5, n_iter=5, momentum=0.1, sampling_stride=3, **kwargs):\n",
        "        super(ChannelDeconv2D, self).__init__(**kwargs)\n",
        "\n",
        "        self.eps = eps\n",
        "        self.n_iter = n_iter\n",
        "        self.momentum = momentum\n",
        "        self.block = block\n",
        "        self.sampling_stride = sampling_stride\n",
        "\n",
        "        self.running_mean1 = tf.Variable(tf.zeros([block, 1]), trainable=False, dtype=self.dtype)\n",
        "        self.running_mean2 = tf.Variable(tf.zeros([]), trainable=False, dtype=self.dtype)\n",
        "        self.running_var = tf.Variable(tf.ones([]), trainable=False, dtype=self.dtype)\n",
        "        self.running_deconv = tf.Variable(tf.eye(block), trainable=False, dtype=self.dtype)\n",
        "        self.num_batches_tracked = tf.Variable(tf.convert_to_tensor(0, dtype=tf.int64), trainable=False)\n",
        "\n",
        "        self.block_eye = tf.eye(block)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        in_channels = input_shape[-1]\n",
        "        self.in_channels = in_channels\n",
        "\n",
        "        if int(in_channels / self.block) * self.block == 0:\n",
        "            raise ValueError(\"`block` must be smaller than in_channels.\")\n",
        "\n",
        "        # change rank based on 3d or 4d tensor input\n",
        "        channel_axis = -1\n",
        "        self.input_spec = tf.keras.layers.InputSpec(min_ndim=2,\n",
        "                                                    max_ndim=4,\n",
        "                                                    axes={channel_axis: in_channels})\n",
        "\n",
        "        self.built = True\n",
        "\n",
        "    #@tf.function\n",
        "    def call(self, x, training=None):\n",
        "        x_shape = tf.shape(x)\n",
        "        x_original_shape = x_shape\n",
        "\n",
        "        if len(x.shape) == 2:\n",
        "            x = tf.reshape(x, [x_shape[0], 1, 1, x_shape[1]])\n",
        "\n",
        "        x_shape = tf.shape(x)\n",
        "\n",
        "        N, H, W, C = x_shape[0], x_shape[1], x_shape[2], x_shape[3]\n",
        "        block = self.block\n",
        "\n",
        "        # take the first c channels out for deconv\n",
        "        c = tf.cast(C / block, tf.int32) * block\n",
        "\n",
        "        # step 1. remove mean\n",
        "        if c != C:\n",
        "            x1 = tf.reshape(tf.transpose(x[:, :, :, :c], [3, 0, 1, 2]), [block, -1])\n",
        "        else:\n",
        "            x1 = tf.reshape(tf.transpose(x, [3, 0, 1, 2]), [block, -1])\n",
        "\n",
        "        if self.sampling_stride > 1 and H >= self.sampling_stride and W >= self.sampling_stride:\n",
        "            x1_s = x1[:, ::self.sampling_stride ** 2]\n",
        "        else:\n",
        "            x1_s = x1\n",
        "\n",
        "        mean1 = tf.reduce_mean(x1_s, axis=-1, keepdims=True)  # [blocks, 1]\n",
        "\n",
        "        if self.num_batches_tracked == 0:\n",
        "            self.running_mean1.assign(mean1)\n",
        "\n",
        "        if training:\n",
        "            running_mean1 = self.momentum * mean1 + (1. - self.momentum) * self.running_mean1\n",
        "            self.running_mean1.assign(running_mean1)\n",
        "        else:\n",
        "            mean1 = self.running_mean1\n",
        "\n",
        "        x1 = x1 - mean1\n",
        "\n",
        "        # step 2. calculate deconv@x1 = cov^(-0.5)@x1\n",
        "        if training:\n",
        "            scale_ = tf.cast(tf.shape(x1_s)[1], x1_s.dtype)\n",
        "            cov = (tf.matmul(x1_s, tf.transpose(x1_s)) / scale_) + self.eps * self.block_eye\n",
        "            deconv = isqrt_newton_schulz_autograd(cov, self.n_iter)\n",
        "        else:\n",
        "            deconv = self.running_deconv\n",
        "\n",
        "        if self.num_batches_tracked == 0:\n",
        "            self.running_deconv.assign(deconv)\n",
        "\n",
        "        if training:\n",
        "            running_deconv = self.momentum * deconv + (1. - self.momentum) * self.running_deconv\n",
        "            self.running_deconv.assign(running_deconv)\n",
        "        else:\n",
        "            deconv = self.running_deconv\n",
        "\n",
        "        x1 = tf.matmul(deconv, x1)\n",
        "\n",
        "        # reshape to N,c,J,W\n",
        "        x1 = tf.reshape(x1, [c, N, H, W])\n",
        "        x1 = tf.transpose(x1, [1, 2, 3, 0])  # [N, H, W, C]\n",
        "\n",
        "        # normalize the remaining channels\n",
        "        if c != C:\n",
        "            x_tmp = tf.reshape(x[:, :, :, c:], [N, -1])\n",
        "\n",
        "            if self.sampling_stride > 1 and H >= self.sampling_stride and W >= self.sampling_stride:\n",
        "                x_s = x_tmp[:, ::self.sampling_stride ** 2]\n",
        "            else:\n",
        "                x_s = x_tmp\n",
        "\n",
        "            mean2, var = tf.nn.moments(x_s, axes=[0, 1])\n",
        "\n",
        "            if self.num_batches_tracked == 0:\n",
        "                self.running_mean2.assign(mean2)\n",
        "                self.running_var.assign(var)\n",
        "\n",
        "            if training:\n",
        "                running_mean2 = self.momentum * mean2 + (1. - self.momentum) * self.running_mean2\n",
        "                running_var = self.momentum * var + (1. - self.momentum) * self.running_var\n",
        "                self.running_mean2.assign(running_mean2)\n",
        "                self.running_var.assign(running_var)\n",
        "            else:\n",
        "                mean2 = self.running_mean2\n",
        "                var = self.running_var\n",
        "\n",
        "            x_tmp = tf.sqrt((x[:, :, :, c:] - mean2) / (var + self.eps))\n",
        "            x1 = tf.concat([x1, x_tmp], axis=-1)\n",
        "\n",
        "        if training:\n",
        "            self.num_batches_tracked.assign_add(1)\n",
        "\n",
        "        if len(x_original_shape) == 2:\n",
        "            x1 = tf.reshape(x1, x_original_shape)\n",
        "        else:\n",
        "            x_intshape = x.shape\n",
        "            x1 = tf.ensure_shape(x1, x_intshape)\n",
        "\n",
        "        return x1\n",
        "\n",
        "\n",
        "class FastDeconv2D(Conv):\n",
        "    \n",
        "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding='valid', dilation_rate=1,\n",
        "                 activation=None, use_bias=True, groups=1, eps=1e-2, n_iter=2, momentum=0.1, block=64,\n",
        "                 sampling_stride=3, freeze=False, freeze_iter=100, kernel_initializer='he_uniform',\n",
        "                 bias_initializer=BiasHeUniform(), **kwargs):\n",
        "        self.in_channels = in_channels\n",
        "        self.groups = groups\n",
        "        self.momentum = momentum\n",
        "        self.n_iter = n_iter\n",
        "        self.eps = eps\n",
        "        self.counter = 0\n",
        "        self.track_running_stats = True\n",
        "\n",
        "        if in_channels % self.groups != 0:\n",
        "            raise ValueError(\n",
        "                'The number of input channels must be evenly divisible by the number '\n",
        "                'of groups. Received groups={}, but the input has {} channels '.format(self.groups,\n",
        "                                                                                       in_channels))\n",
        "        if out_channels is not None and out_channels % self.groups != 0:\n",
        "            raise ValueError(\n",
        "                'The number of filters must be evenly divisible by the number of '\n",
        "                'groups. Received: groups={}, filters={}'.format(groups, out_channels))\n",
        "\n",
        "        super(FastDeconv2D, self).__init__(\n",
        "            2, out_channels, kernel_size, stride, padding, dilation_rate=dilation_rate,\n",
        "            activation=activation, use_bias=use_bias, kernel_initializer=kernel_initializer,\n",
        "            bias_initializer=bias_initializer, **kwargs\n",
        "        )\n",
        "\n",
        "        if block > in_channels:\n",
        "            block = in_channels\n",
        "        else:\n",
        "            if in_channels % block != 0:\n",
        "                block = math.gcd(block, in_channels)\n",
        "                print(\"`in_channels` not divisible by `block`, computing new `block` value as %d\" % (block))\n",
        "\n",
        "        if groups > 1:\n",
        "            block = in_channels // groups\n",
        "\n",
        "        self.block = block\n",
        "\n",
        "        kernel_size_int_0 = kernel_size[0] if type(kernel_size) in (list, tuple) else kernel_size\n",
        "        kernel_size_int_1 = kernel_size[1] if type(kernel_size) in (list, tuple) else kernel_size\n",
        "        self.num_features = kernel_size_int_0 * kernel_size_int_1 * block\n",
        "\n",
        "        if self.groups == 1:\n",
        "            self.running_mean = tf.Variable(tf.zeros(self.num_features), trainable=False, dtype=self.dtype)\n",
        "            self.running_deconv = tf.Variable(tf.eye(self.num_features), trainable=False, dtype=self.dtype)\n",
        "        else:\n",
        "            self.running_mean = tf.Variable(tf.zeros(kernel_size_int_0 * kernel_size_int_1 * in_channels),\n",
        "                                            trainable=False, dtype=self.dtype)\n",
        "\n",
        "            deconv_buff = tf.eye(self.num_features)\n",
        "            deconv_buff = tf.expand_dims(deconv_buff, axis=0)\n",
        "            deconv_buff = tf.tile(deconv_buff, [in_channels // block, 1, 1])\n",
        "            self.running_deconv = tf.Variable(deconv_buff, trainable=False, dtype=self.dtype)\n",
        "\n",
        "        stride_int = stride[0] if type(stride) in (list, tuple) else stride\n",
        "        self.sampling_stride = sampling_stride * stride_int\n",
        "        self.counter = tf.Variable(tf.convert_to_tensor(0, dtype=tf.int64), trainable=False)\n",
        "        self.freeze_iter = freeze_iter\n",
        "        self.freeze = freeze\n",
        "\n",
        "    \n",
        "    def build(self, input_shape):\n",
        "        input_shape = tf.TensorShape(input_shape)\n",
        "        input_channel = self._get_input_channel(input_shape)\n",
        "        kernel_shape = self.kernel_size + (input_channel // self.groups, self.filters)\n",
        "\n",
        "        self.kernel = self.add_weight(\n",
        "            name='kernel',\n",
        "            shape=kernel_shape,\n",
        "            initializer=self.kernel_initializer,\n",
        "            regularizer=self.kernel_regularizer,\n",
        "            constraint=self.kernel_constraint,\n",
        "            trainable=True,\n",
        "            dtype=self.dtype)\n",
        "        if self.use_bias:\n",
        "            self.bias = self.add_weight(\n",
        "                name='bias',\n",
        "                shape=(self.filters,),\n",
        "                initializer=self.bias_initializer,\n",
        "                regularizer=self.bias_regularizer,\n",
        "                constraint=self.bias_constraint,\n",
        "                trainable=True,\n",
        "                dtype=self.dtype)\n",
        "        else:\n",
        "            self.bias = None\n",
        "        channel_axis = self._get_channel_axis()\n",
        "\n",
        "        # change rank based on 3d or 4d tensor input\n",
        "        ndim = len(input_shape)\n",
        "\n",
        "        self.input_spec = tf.keras.layers.InputSpec(min_ndim=3,\n",
        "                                                    max_ndim=4,\n",
        "                                                    axes={channel_axis: input_channel})\n",
        "\n",
        "        self._build_conv_op_input_shape = input_shape\n",
        "        self._build_input_channel = input_channel\n",
        "        self._padding_op = self._get_padding_op()\n",
        "        self._conv_op_data_format = conv_utils.convert_data_format(\n",
        "            self.data_format, self.rank + 2)\n",
        "        self.built = True\n",
        "\n",
        "    #@tf.function(experimental_compile=False)\n",
        "    def call(self, x, training=None):\n",
        "        x_shape = tf.shape(x)\n",
        "        N, H, W, C = x_shape[0], x_shape[1], x_shape[2], x_shape[3]\n",
        "\n",
        "        block = self.block\n",
        "        frozen = self.freeze and (self.counter > self.freeze_iter)\n",
        "\n",
        "        if training and self.track_running_stats:\n",
        "            counter = self.counter + 1\n",
        "            counter = counter % (self.freeze_iter * 10)\n",
        "            self.counter.assign(counter)\n",
        "\n",
        "        if training and (not frozen):\n",
        "\n",
        "            # 1. im2col: N x cols x pixels -> N*pixles x cols\n",
        "            if self.kernel_size[0] > 1:\n",
        "                # [N, L, L, C * K^2]\n",
        "                X = tf.image.extract_patches(x,\n",
        "                                             sizes=[1] + list(self.kernel_size) + [1],\n",
        "                                             strides=[1, self.sampling_stride, self.sampling_stride, 1],\n",
        "                                             rates=[1, self.dilation_rate[0], self.dilation_rate[1], 1],\n",
        "                                             padding=str(self.padding).upper())\n",
        "\n",
        "                X = tf.reshape(X, [N, -1, C * self.kernel_size[0] * self.kernel_size[1]])  # [N, L^2, C * K^2]\n",
        "\n",
        "            else:\n",
        "                # channel wise ([N, H, W, C] -> [N * H * W, C] -> [N * H / S * W / S, C]\n",
        "                X = tf.reshape(x, [-1, C])[::self.sampling_stride ** 2, :]\n",
        "\n",
        "            if self.groups == 1:\n",
        "                # (C//B*N*pixels,k*k*B)\n",
        "                X = tf.reshape(X, [-1, self.num_features, C // block])\n",
        "                X = tf.transpose(X, [0, 2, 1])\n",
        "                X = tf.reshape(X, [-1, self.num_features])\n",
        "            else:\n",
        "                X_shape_ = tf.shape(X)\n",
        "                X = tf.reshape(X, [-1, X_shape_[-1]])  # [N, L^2, C * K^2] -> [N * L^2, C * K^2]\n",
        "\n",
        "            # 2. subtract mean\n",
        "            X_mean = tf.reduce_mean(X, axis=0)\n",
        "            X = X - tf.expand_dims(X_mean, axis=0)\n",
        "\n",
        "            # 3. calculate COV, COV^(-0.5), then deconv\n",
        "            if self.groups == 1:\n",
        "                scale = tf.cast(tf.shape(X)[0], X.dtype)\n",
        "                Id = tf.eye(X.shape[1], dtype=X.dtype)\n",
        "                # addmm op\n",
        "                Cov = self.eps * Id + (1. / scale) * tf.matmul(tf.transpose(X), X)\n",
        "                deconv = isqrt_newton_schulz_autograd(Cov, self.n_iter)\n",
        "            else:\n",
        "                X = tf.reshape(X, [-1, self.groups, self.num_features])\n",
        "                X = tf.transpose(X, [1, 0, 2])  # [groups, -1, num_features]\n",
        "\n",
        "                Id = tf.eye(self.num_features, dtype=X.dtype)\n",
        "                Id = tf.broadcast_to(Id, [self.groups, self.num_features, self.num_features])\n",
        "\n",
        "                scale = tf.cast(tf.shape(X)[1], X.dtype)\n",
        "                Cov = self.eps * Id + (1. / scale) * tf.matmul(tf.transpose(X, [0, 2, 1]), X)\n",
        "\n",
        "                deconv = isqrt_newton_schulz_autograd_batch(Cov, self.n_iter)\n",
        "\n",
        "            if self.track_running_stats:\n",
        "                running_mean = self.momentum * X_mean + (1. - self.momentum) * self.running_mean\n",
        "                running_deconv = self.momentum * deconv + (1. - self.momentum) * self.running_deconv\n",
        "\n",
        "                # track stats for evaluation\n",
        "                self.running_mean.assign(running_mean)\n",
        "                self.running_deconv.assign(running_deconv)\n",
        "\n",
        "        else:\n",
        "            X_mean = self.running_mean\n",
        "            deconv = self.running_deconv\n",
        "\n",
        "        # 4. X * deconv * conv = X * (deconv * conv)\n",
        "        if self.groups == 1:\n",
        "            w = tf.reshape(self.kernel, [C // block, self.num_features, -1])\n",
        "            w = tf.transpose(w, [0, 2, 1])\n",
        "            w = tf.reshape(w, [-1, self.num_features])\n",
        "            w = tf.matmul(w, deconv)\n",
        "\n",
        "            if self.use_bias:\n",
        "                b_dash = tf.matmul(w, (tf.expand_dims(X_mean, axis=-1)))\n",
        "                b_dash = tf.reshape(b_dash, [self.filters, -1])\n",
        "                b_dash = tf.reduce_sum(b_dash, axis=1)\n",
        "                b = self.bias - b_dash\n",
        "            else:\n",
        "                b = 0.\n",
        "\n",
        "            w = tf.reshape(w, [C // block, -1, self.num_features])\n",
        "            w = tf.transpose(w, [0, 2, 1])\n",
        "\n",
        "        else:\n",
        "            w = tf.reshape(self.kernel, [C // block, -1, self.num_features])\n",
        "            w = tf.matmul(w, deconv)\n",
        "\n",
        "            if self.use_bias:\n",
        "                b_dash = tf.matmul(w, tf.reshape(X_mean, [-1, self.num_features, 1]))\n",
        "                b_dash = tf.reshape(b_dash, self.bias.shape)\n",
        "                b = self.bias - b_dash\n",
        "            else:\n",
        "                b = 0.\n",
        "\n",
        "        w = tf.reshape(w, self.kernel.shape)\n",
        "\n",
        "        x = tf.nn.conv2d(x, w, self.strides, str(self.padding).upper(), dilations=self.dilation_rate)\n",
        "        if self.use_bias:\n",
        "            x = tf.nn.bias_add(x, b, data_format=\"NHWC\")\n",
        "\n",
        "        if self.activation is not None:\n",
        "            return self.activation(x)\n",
        "        else:\n",
        "            return x\n",
        "\n",
        "\n",
        "\"\"\" 1D Compat layers \"\"\"\n",
        "\n",
        "\n",
        "class ChannelDeconv1D(ChannelDeconv2D):\n",
        "\n",
        "    def __init__(self, block, eps=1e-5, n_iter=5, momentum=0.1, sampling_stride=3, **kwargs):\n",
        "        super(ChannelDeconv1D, self).__init__(block=block, eps=eps, n_iter=n_iter,\n",
        "                                              momentum=momentum, sampling_stride=sampling_stride, **kwargs)\n",
        "\n",
        "        self.input_spec = tf.keras.layers.InputSpec(min_ndim=2, max_ndim=3)\n",
        "\n",
        "    #@tf.function\n",
        "    def call(self, x, training=None):\n",
        "        # insert dummy dimension in time channel\n",
        "        shape = x.shape\n",
        "\n",
        "        if len(shape) == 3:\n",
        "            x_expanded = tf.expand_dims(x, axis=2)  # [N, T, 1, C]\n",
        "        else:\n",
        "            x_expanded = x\n",
        "\n",
        "        out = super(ChannelDeconv1D, self).call(x_expanded, training=training)\n",
        "\n",
        "        if len(shape) == 3:\n",
        "            # remove dummy dimension\n",
        "            x = tf.squeeze(out, axis=2)  # [N, T / stride, C']\n",
        "        else:\n",
        "            x = out\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "class FastDeconv1D(FastDeconv2D):\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding='valid', dilation_rate=1,\n",
        "                 activation=None, use_bias=True, groups=1, eps=1e-5, n_iter=5, momentum=0.1, block=64,\n",
        "                 sampling_stride=3, freeze=False, freeze_iter=100, kernel_initializer='he_uniform',\n",
        "                 bias_initializer=BiasHeUniform(), **kwargs):\n",
        "        kernel_size = (kernel_size, 1)\n",
        "        stride = (stride, 1)\n",
        "        super(FastDeconv1D, self).__init__(in_channels=in_channels, out_channels=out_channels,\n",
        "                                           kernel_size=kernel_size, stride=stride, padding=padding,\n",
        "                                           dilation_rate=dilation_rate, activation=activation,\n",
        "                                           use_bias=use_bias, groups=groups, eps=eps,\n",
        "                                           n_iter=n_iter, momentum=momentum, block=block,\n",
        "                                           sampling_stride=sampling_stride, freeze=freeze, freeze_iter=freeze_iter,\n",
        "                                           kernel_initializer=kernel_initializer, bias_initializer=bias_initializer,\n",
        "                                           **kwargs)\n",
        "\n",
        "        self.input_spec = tf.keras.layers.InputSpec(ndim=3)\n",
        "\n",
        "    #@tf.function(experimental_compile=False)\n",
        "    def call(self, x, training=None):\n",
        "        # insert dummy dimension in time channel\n",
        "        x_expanded = tf.expand_dims(x, axis=2)  # [N, T, 1, C]\n",
        "\n",
        "        out = super(FastDeconv1D, self).call(x_expanded, training=training)\n",
        "\n",
        "        # remove dummy dimension\n",
        "        x = tf.squeeze(out, axis=2)  # [N, T / stride, C']\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-10-1cbffb9d4d70>:3: experimental_run_functions_eagerly (from tensorflow.python.eager.def_function) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.config.run_functions_eagerly` instead of the experimental version.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bLjzhJIJmsGH"
      },
      "source": [
        "### Deep Deconv Residual UNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OptogdGxagkM"
      },
      "source": [
        "from keras.models import *\n",
        "from tensorflow.keras.layers import Input, Conv2D, UpSampling2D, BatchNormalization, Activation, add, concatenate, Add\n",
        "\n",
        "\n",
        "def bn_act(x, act=True):\n",
        "    x = BatchNormalization()(x)\n",
        "    if act == True:\n",
        "        x = Activation(\"relu\")(x)\n",
        "    return x\n",
        "\n",
        "def conv_block(x, filters, kernel_size=(3, 3), padding=\"same\", strides=1):\n",
        "    conv = bn_act(x)\n",
        "    conv = FastDeconv2D(in_channels=1, out_channels=filters, kernel_size=kernel_size, padding=padding, stride=strides)(conv)\n",
        "    # conv = Conv2D(filters, kernel_size, padding=padding, strides=strides)(conv)\n",
        "    return conv\n",
        "\n",
        "def stem(x, filters, kernel_size=(3, 3), padding=\"same\", strides=1):\n",
        "    conv = FastDeconv2D(in_channels=1, out_channels=filters, kernel_size=kernel_size, padding=padding, stride=strides)(x)\n",
        "    # conv = Conv2D(filters, kernel_size, padding=padding, strides=strides)(x)\n",
        "    conv = conv_block(conv, filters, kernel_size=kernel_size, padding=padding, strides=strides)\n",
        "    shortcut = FastDeconv2D(in_channels=1, out_channels=filters, kernel_size=(1, 1), padding=padding, stride=strides)(x)\n",
        "    # shortcut = Conv2D(filters, kernel_size=(1, 1), padding=padding, strides=strides)(x)\n",
        "    shortcut = bn_act(shortcut, act=False)\n",
        "    \n",
        "    output = Add()([conv, shortcut])\n",
        "    return output\n",
        "\n",
        "def residual_block(x, filters, kernel_size=(3, 3), padding=\"same\", strides=1):\n",
        "    res = conv_block(x, filters, kernel_size=kernel_size, padding=padding, strides=strides)\n",
        "    res = conv_block(res, filters, kernel_size=kernel_size, padding=padding, strides=1)\n",
        "    shortcut = FastDeconv2D(in_channels=1, out_channels=filters, kernel_size=(1, 1), padding=padding, stride=strides)(x)\n",
        "    # shortcut = Conv2D(filters, kernel_size=(1, 1), padding=padding, strides=strides)(x)\n",
        "    shortcut = bn_act(shortcut, act=False)\n",
        "    \n",
        "    output = Add()([shortcut, res])\n",
        "    return output\n",
        "\n",
        "def upsample_concat_block(x, xskip):\n",
        "    u = UpSampling2D((2, 2))(x)\n",
        "    c = Concatenate()([u, xskip])\n",
        "    return c"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwz_78iOairE"
      },
      "source": [
        "def ResUNet(image_size):\n",
        "    f = [16, 32, 64, 128, 256]\n",
        "    inputs = keras.layers.Input((image_size, image_size, 6))\n",
        "    \n",
        "    ## Encoder\n",
        "    e0 = inputs\n",
        "    e1 = stem(e0, f[0])\n",
        "    e2 = residual_block(e1, f[1], strides=2)\n",
        "    e3 = residual_block(e2, f[2], strides=2)\n",
        "    e4 = residual_block(e3, f[3], strides=2)\n",
        "    e5 = residual_block(e4, f[4], strides=2)\n",
        "    \n",
        "    ## Bridge\n",
        "    b0 = conv_block(e5, f[4], strides=1)\n",
        "    b1 = conv_block(b0, f[4], strides=1)\n",
        "    \n",
        "    ## Decoder\n",
        "    u1 = upsample_concat_block(b1, e4)\n",
        "    d1 = residual_block(u1, f[4])\n",
        "    \n",
        "    u2 = upsample_concat_block(d1, e3)\n",
        "    d2 = residual_block(u2, f[3])\n",
        "    \n",
        "    u3 = upsample_concat_block(d2, e2)\n",
        "    d3 = residual_block(u3, f[2])\n",
        "    \n",
        "    u4 = upsample_concat_block(d3, e1)\n",
        "    d4 = residual_block(u4, f[1])\n",
        "    \n",
        "    outputs = Conv2D(1, (1, 1), padding=\"same\", activation=\"sigmoid\")(d4)\n",
        "    model = keras.models.Model(inputs, outputs)\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jfh6SCLialE_"
      },
      "source": [
        "smooth = 1.\n",
        "\n",
        "def dice_coef(y_true, y_pred):\n",
        "    y_true_f = tf.layers.flatten(y_true)\n",
        "    y_pred_f = tf.layers.flatten(y_pred)\n",
        "    intersection = tf.reduce_sum(y_true_f * y_pred_f)\n",
        "    return (2. * intersection + smooth) / (tf.reduce_sum(y_true_f) + tf.reduce_sum(y_pred_f) + smooth)\n",
        "\n",
        "\n",
        "def dice_coef_loss(y_true, y_pred):\n",
        "    return 1.0 - dice_coef(y_true, y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7wPbhXDRanRR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "104b9313-503f-4a2d-955b-1e852760bb9b"
      },
      "source": [
        "model = ResUNet(128)\n",
        "adam = keras.optimizers.Adam()\n",
        "model.compile(optimizer=adam,loss = 'binary_crossentropy', metrics = metrics)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 128, 128, 6) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "fast_deconv2d (FastDeconv2D)    (None, 128, 128, 16) 971         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 128, 128, 16) 64          fast_deconv2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 128, 128, 16) 0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "fast_deconv2d_2 (FastDeconv2D)  (None, 128, 128, 16) 115         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "fast_deconv2d_1 (FastDeconv2D)  (None, 128, 128, 16) 2411        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 128, 128, 16) 64          fast_deconv2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 128, 128, 16) 0           fast_deconv2d_1[0][0]            \n",
            "                                                                 batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 128, 128, 16) 64          add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 128, 128, 16) 0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "fast_deconv2d_3 (FastDeconv2D)  (None, 64, 64, 32)   4731        activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 64, 64, 32)   128         fast_deconv2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "fast_deconv2d_5 (FastDeconv2D)  (None, 64, 64, 32)   547         add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 64, 64, 32)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 64, 64, 32)   128         fast_deconv2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "fast_deconv2d_4 (FastDeconv2D)  (None, 64, 64, 32)   9339        activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 64, 64, 32)   0           batch_normalization_4[0][0]      \n",
            "                                                                 fast_deconv2d_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 64, 64, 32)   128         add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 64, 64, 32)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "fast_deconv2d_6 (FastDeconv2D)  (None, 32, 32, 64)   18587       activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 32, 32, 64)   256         fast_deconv2d_6[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "fast_deconv2d_8 (FastDeconv2D)  (None, 32, 32, 64)   2115        add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 32, 32, 64)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 32, 32, 64)   256         fast_deconv2d_8[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "fast_deconv2d_7 (FastDeconv2D)  (None, 32, 32, 64)   37019       activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 32, 32, 64)   0           batch_normalization_7[0][0]      \n",
            "                                                                 fast_deconv2d_7[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 32, 32, 64)   256         add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 32, 32, 64)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "fast_deconv2d_9 (FastDeconv2D)  (None, 16, 16, 128)  73947       activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 16, 16, 128)  512         fast_deconv2d_9[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "fast_deconv2d_11 (FastDeconv2D) (None, 16, 16, 128)  8323        add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 16, 16, 128)  0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 16, 16, 128)  512         fast_deconv2d_11[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "fast_deconv2d_10 (FastDeconv2D) (None, 16, 16, 128)  147675      activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 16, 16, 128)  0           batch_normalization_10[0][0]     \n",
            "                                                                 fast_deconv2d_10[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 16, 16, 128)  512         add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 16, 16, 128)  0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "fast_deconv2d_12 (FastDeconv2D) (None, 8, 8, 256)    295259      activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 8, 8, 256)    1024        fast_deconv2d_12[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "fast_deconv2d_14 (FastDeconv2D) (None, 8, 8, 256)    33027       add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 8, 8, 256)    0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 8, 8, 256)    1024        fast_deconv2d_14[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "fast_deconv2d_13 (FastDeconv2D) (None, 8, 8, 256)    590171      activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 8, 8, 256)    0           batch_normalization_13[0][0]     \n",
            "                                                                 fast_deconv2d_13[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 8, 8, 256)    1024        add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 8, 8, 256)    0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "fast_deconv2d_15 (FastDeconv2D) (None, 8, 8, 256)    590171      activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 8, 8, 256)    1024        fast_deconv2d_15[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 8, 8, 256)    0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "fast_deconv2d_16 (FastDeconv2D) (None, 8, 8, 256)    590171      activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d (UpSampling2D)    (None, 16, 16, 256)  0           fast_deconv2d_16[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 16, 16, 384)  0           up_sampling2d[0][0]              \n",
            "                                                                 add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 16, 16, 384)  1536        concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 16, 16, 384)  0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "fast_deconv2d_17 (FastDeconv2D) (None, 16, 16, 256)  885083      activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 16, 16, 256)  1024        fast_deconv2d_17[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "fast_deconv2d_19 (FastDeconv2D) (None, 16, 16, 256)  98563       concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 16, 16, 256)  0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 16, 16, 256)  1024        fast_deconv2d_19[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "fast_deconv2d_18 (FastDeconv2D) (None, 16, 16, 256)  590171      activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 16, 16, 256)  0           batch_normalization_18[0][0]     \n",
            "                                                                 fast_deconv2d_18[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_1 (UpSampling2D)  (None, 32, 32, 256)  0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 32, 32, 320)  0           up_sampling2d_1[0][0]            \n",
            "                                                                 add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 32, 32, 320)  1280        concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 32, 32, 320)  0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "fast_deconv2d_20 (FastDeconv2D) (None, 32, 32, 128)  368859      activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 32, 32, 128)  512         fast_deconv2d_20[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "fast_deconv2d_22 (FastDeconv2D) (None, 32, 32, 128)  41091       concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 32, 32, 128)  0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 32, 32, 128)  512         fast_deconv2d_22[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "fast_deconv2d_21 (FastDeconv2D) (None, 32, 32, 128)  147675      activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 32, 32, 128)  0           batch_normalization_21[0][0]     \n",
            "                                                                 fast_deconv2d_21[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_2 (UpSampling2D)  (None, 64, 64, 128)  0           add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 64, 64, 160)  0           up_sampling2d_2[0][0]            \n",
            "                                                                 add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 64, 64, 160)  640         concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 64, 64, 160)  0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "fast_deconv2d_23 (FastDeconv2D) (None, 64, 64, 64)   92315       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 64, 64, 64)   256         fast_deconv2d_23[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "fast_deconv2d_25 (FastDeconv2D) (None, 64, 64, 64)   10307       concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 64, 64, 64)   0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 64, 64, 64)   256         fast_deconv2d_25[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "fast_deconv2d_24 (FastDeconv2D) (None, 64, 64, 64)   37019       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 64, 64, 64)   0           batch_normalization_24[0][0]     \n",
            "                                                                 fast_deconv2d_24[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_3 (UpSampling2D)  (None, 128, 128, 64) 0           add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 128, 128, 80) 0           up_sampling2d_3[0][0]            \n",
            "                                                                 add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 128, 128, 80) 320         concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 128, 128, 80) 0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "fast_deconv2d_26 (FastDeconv2D) (None, 128, 128, 32) 23163       activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 128, 128, 32) 128         fast_deconv2d_26[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "fast_deconv2d_28 (FastDeconv2D) (None, 128, 128, 32) 2595        concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 128, 128, 32) 0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 128, 128, 32) 128         fast_deconv2d_28[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "fast_deconv2d_27 (FastDeconv2D) (None, 128, 128, 32) 9339        activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 128, 128, 32) 0           batch_normalization_27[0][0]     \n",
            "                                                                 fast_deconv2d_27[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 128, 128, 1)  33          add_8[0][0]                      \n",
            "==================================================================================================\n",
            "Total params: 4,725,384\n",
            "Trainable params: 4,716,241\n",
            "Non-trainable params: 9,143\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kk8qSIoiapU4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48cc6061-f194-4c80-f094-68e084a1017d"
      },
      "source": [
        "import os\n",
        "\n",
        "# Model training - Results are saved in a .csv file\n",
        "\n",
        "# size of the tiles\n",
        "size = 128\n",
        "# Sampling method\n",
        "sampling = \"regular\"\n",
        "# number of filters \n",
        "filters = [16]\n",
        "# lr = 0.001\n",
        "lr = [10e-4]\n",
        "# batch sizes \n",
        "batch_size = [16]\n",
        "#input shape\n",
        "input_shape = (128, 128, 6)\n",
        "\n",
        "# dictionary that will save the results\n",
        "dic = {}\n",
        "\n",
        "# Hyperparameters\n",
        "dic[\"model\"] = []\n",
        "dic[\"batch_size\"] = []\n",
        "dic[\"learning_rate\"] = []\n",
        "dic[\"filters\"] = []\n",
        "\n",
        "# test area 1\n",
        "dic[\"precision_area_1\"] = []\n",
        "dic[\"recall_area_1\"] = []\n",
        "dic[\"f1_score_area_1\"] = []\n",
        "dic[\"iou_score_area_1\"] = []\n",
        "\n",
        "# test area 2\n",
        "dic[\"precision_area_2\"] = []\n",
        "dic[\"recall_area_2\"] = []\n",
        "dic[\"f1_score_area_2\"] = []\n",
        "dic[\"iou_score_area_2\"] = []\n",
        "\n",
        "\n",
        "\n",
        "# loop over all the filters in the filter list\n",
        "for fiilter in filters:\n",
        "    # loop over the learning rates (used to evalute 0.01 and 0.0001 without good results)\n",
        "    for learning_rate in lr:\n",
        "        # loop over all batch sizes in batch_size list\n",
        "        for batch in batch_size:\n",
        "            # load the model\n",
        "            model = ResUNet(128)\n",
        "            adam = keras.optimizers.Adam()\n",
        "            model.compile(optimizer=adam,loss = 'binary_crossentropy', metrics = metrics)\n",
        "\n",
        "            print(fiilter, learning_rate,batch)\n",
        "            # fit the model 30% of the dataset was used as validation\n",
        "            history = model.fit(X_train,Y_train,batch_size = batch,epochs=2,validation_split=0.3)\n",
        "\n",
        "            # summarize history for iou score\n",
        "            plt.plot(history.history['iou_score'])\n",
        "            plt.plot(history.history['val_iou_score'])\n",
        "            plt.title('model accuracy')\n",
        "            plt.ylabel('accuracy')\n",
        "            plt.xlabel('epoch')\n",
        "            plt.legend(['train', 'validation'], loc='upper left')\n",
        "            # save plots\n",
        "            plt.savefig(f\"/content/unet_{sampling}_size_{size}_filters_{fiilter}_batch_size_{batch}_lr_{learning_rate}_iou_score.png\")\n",
        "            plt.show()\n",
        "            # summarize history for loss\n",
        "            plt.plot(history.history['loss'])\n",
        "            plt.plot(history.history['val_loss'])\n",
        "            plt.title('model loss')\n",
        "            plt.ylabel('loss')\n",
        "            plt.xlabel('epoch')\n",
        "            plt.legend(['train', 'validation'], loc='upper left')\n",
        "            plt.savefig(f\"/content/unet_{sampling}_size_{size}_filters_{fiilter}_batch_size_{batch}_lr_{learning_rate}_val_loss.png\")\n",
        "            plt.show()\n",
        "            \n",
        "            # load unet to evaluate the test data\n",
        "            unet_original = ResUNet(1024)\n",
        "\n",
        "            unet_original.compile(optimizer=adam,loss = 'binary_crossentropy', metrics = metrics)\n",
        "            # load the last saved weight from the training\n",
        "            # unet_original.load_weights(f\"/content/unet_{sampling}_size_{size}_filters_{fiilter}_batch_size_{batch}_lr_{learning_rate}.hdf5\")\n",
        "            \n",
        "            \n",
        "           # Evaluate test area 1\n",
        "            res_1 = unet_original.evaluate(X_test_area_1,Y_test_area_1)\n",
        "            \n",
        "            # Evaluate test area 2\n",
        "            res_2 = unet_original.evaluate(X_test_area_2,Y_test_area_2)\n",
        "\n",
        "            # Data to plot the predicted output\n",
        "            preds_train_1 = unet_original.predict(X_test_area_1, verbose=1)\n",
        "            preds_train_t1 = (preds_train_1 > 0.5).astype(np.uint8)\n",
        "            preds_train_2 = unet_original.predict(X_test_area_2, verbose=1)\n",
        "            preds_train_t2 = (preds_train_2 > 0.5).astype(np.uint8)\n",
        "\n",
        "\n",
        "            # save results on the dictionary\n",
        "            dic[\"model\"].append(\"Unet\")\n",
        "            dic[\"batch_size\"].append(batch)\n",
        "            dic[\"learning_rate\"].append(learning_rate)\n",
        "            dic[\"filters\"].append(fiilter)\n",
        "            dic[\"precision_area_1\"].append(res_1[1])\n",
        "            dic[\"recall_area_1\"].append(res_1[2])\n",
        "            dic[\"f1_score_area_1\"].append(res_1[3])\n",
        "            dic[\"iou_score_area_1\"].append(res_1[4])\n",
        "           \n",
        "            dic[\"precision_area_2\"].append(res_2[1])\n",
        "            dic[\"recall_area_2\"].append(res_2[2])\n",
        "            dic[\"f1_score_area_2\"].append(res_2[3])\n",
        "            dic[\"iou_score_area_2\"].append(res_2[4])\n",
        "            \n",
        "    \n",
        "            # Plot the results and save the plots\n",
        "            f, axarr = plt.subplots(2,3,figsize=(10,10))\n",
        "            axarr[0,0].imshow(X_test_area_1[0][:,:,:3])\n",
        "            axarr[0,1].imshow(np.squeeze(preds_train_t1[0]))\n",
        "            axarr[0,2].imshow(np.squeeze(Y_test_area_1[0]))\n",
        "            axarr[1,0].imshow(X_test_area_2[0][:,:,:3])\n",
        "            axarr[1,1].imshow(np.squeeze(preds_train_t2[0]))\n",
        "            axarr[1,2].imshow(np.squeeze(Y_test_area_2[0]))\n",
        "            \n",
        "            f.savefig(f\"/content/unet_{sampling}_size_{size}_filters_{fiilter}_batch_size_{batch}_lr_{learning_rate}_result.png\")\n",
        "      \n",
        "            # Convert results to a dataframe\n",
        "            results = pd.DataFrame(dic)\n",
        "            # Export as csv\n",
        "            \n",
        "            results.to_csv(f'/content/unet_{sampling}_size_{size}_filters_{fiilter}_batch_size_{batch}.csv', index = False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "16 0.001 16\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py:3504: UserWarning: Even though the tf.config.experimental_run_functions_eagerly option is set, this option does not apply to tf.data functions. tf.data functions are still traced and executed as graphs.\n",
            "  \"Even though the tf.config.experimental_run_functions_eagerly \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "448/448 [==============================] - 379s 829ms/step - loss: 0.1573 - precision: 0.6578 - recall: 0.3711 - f1-score: 0.4492 - iou_score: 0.3043 - val_loss: 0.1030 - val_precision: 0.7187 - val_recall: 0.6357 - val_f1-score: 0.6736 - val_iou_score: 0.5098\n",
            "Epoch 2/2\n",
            "212/448 [=============>................] - ETA: 3:00 - loss: 0.0727 - precision: 0.8128 - recall: 0.7215 - f1-score: 0.7604 - iou_score: 0.6150"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
